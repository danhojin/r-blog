<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>lasso on A Hugo website</title>
    <link>https://danhojin.github.io/r-blog/tags/lasso/</link>
    <description>Recent content in lasso on A Hugo website</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ko-KR</language>
    <lastBuildDate>Sat, 14 Nov 2020 00:00:00 +0000</lastBuildDate><atom:link href="https://danhojin.github.io/r-blog/tags/lasso/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>교호 작용 선택을 위한 라소 회귀 - glinternet 소개</title>
      <link>https://danhojin.github.io/r-blog/2020/11/14/%EA%B5%90%ED%98%B8-%EC%9E%91%EC%9A%A9-%EB%9D%BC%EC%86%8C-%ED%9A%8C%EA%B7%80-glinternet-%EC%86%8C%EA%B0%9C/</link>
      <pubDate>Sat, 14 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://danhojin.github.io/r-blog/2020/11/14/%EA%B5%90%ED%98%B8-%EC%9E%91%EC%9A%A9-%EB%9D%BC%EC%86%8C-%ED%9A%8C%EA%B7%80-glinternet-%EC%86%8C%EA%B0%9C/</guid>
      <description>glinternet 라소(lasso)나 능형 회귀(ridge regression) 방법은 glmnet 패키지에 잘 구현되어 있으며, 이를 활용하면 특징 변수의 선택을 체계적으로 수행할 수 있다[1]. 이 패키지에는 교차 검증이 구현되어 있어 라그랑주 승수(lagrange multiplier)와 MSE 평균 및 MSE의 분산 관계를 파악할 수 있다. 그리고 그 관계로부터 적절히 선택된 변수를 제안해 준다. 하지만 교호 효과가 유의하나 주 효과가 유의하지 않는 경우에 glmnet은 주 효과를 제거해 버릴 수 있어 문제가 생긴다. 일반적으로 모델 해석을 분명하게 제시하기 위해 유의하지 않더라도 주 효과를 제거하지 않는데[2], 이런 문제를 다루기 위해 glinternet 패키지가 개발되었다[3].</description>
    </item>
    
    <item>
      <title>선형 회귀 모형의 변수 선택: F-검정</title>
      <link>https://danhojin.github.io/r-blog/2020/10/29/%EC%84%A0%ED%98%95-%ED%9A%8C%EA%B7%80-%EB%AA%A8%ED%98%95-%EB%B3%80%EC%88%98-f-%EA%B2%80%EC%A0%95/</link>
      <pubDate>Thu, 29 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://danhojin.github.io/r-blog/2020/10/29/%EC%84%A0%ED%98%95-%ED%9A%8C%EA%B7%80-%EB%AA%A8%ED%98%95-%EB%B3%80%EC%88%98-f-%EA%B2%80%EC%A0%95/</guid>
      <description>다중 선형 회귀에서 특징 변수 선택 선형 회귀에서 오컴의 면도날 원리는 경쟁하는 모형 혹은 모델 간에 보다 적은 수의 특징 변수를 가진 모형을 선택하는 것이 낫다는 것으로 풀어볼 수 있다. 이 원리는 과적합 문제와 연관된다. 데이터 과학에서 가장 주의해야 할 것이 과적합인데 특징 변수가 많을 수록 그 위험이 커지기 때문이다. 지금까지 보지 못 한 새로운 데이터가 등장하였을 때 특히 문제가 된다. 오컴의 면도날 원리를 적용하기 위해서는 특징 변수를 제거해도 회귀 성능이 크게 손상되지 않는다는 점을 확인할 필요가 있다.</description>
    </item>
    
  </channel>
</rss>
