<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>tidymodels on A Hugo website</title>
    <link>https://danhojin.github.io/r-blog/tags/tidymodels/</link>
    <description>Recent content in tidymodels on A Hugo website</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ko-KR</language>
    <lastBuildDate>Tue, 22 Dec 2020 00:00:00 +0000</lastBuildDate><atom:link href="https://danhojin.github.io/r-blog/tags/tidymodels/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>용해도 데이터에 대한 신경망 회귀</title>
      <link>https://danhojin.github.io/r-blog/2020/12/22/%EC%9A%A9%ED%95%B4%EB%8F%84-%EC%8B%A0%EA%B2%BD%EB%A7%9D-%ED%9A%8C%EA%B7%80/</link>
      <pubDate>Tue, 22 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://danhojin.github.io/r-blog/2020/12/22/%EC%9A%A9%ED%95%B4%EB%8F%84-%EC%8B%A0%EA%B2%BD%EB%A7%9D-%ED%9A%8C%EA%B7%80/</guid>
      <description>tidymodels 프레임 내 신경망 회귀 tidymodels 프레임은 tensorflow/keras와 nnet 패키지에 대한 인터페이스를 제공한다. 회귀나 분류 문제를 수행할 수 있으나 제한적인 신경망만 구성할 수 있다. 이 포스트에서는 은닉층이 하나만 존재하는 완전 연결 신경망을 구성하고 K-겹 교차 검증를 이용하여 신경망 튜닝을 수행해 보겠다. 데이터 전처리, 튜닝 변수를 가진 모델 정의, 튜닝 격자 정의, 적합 수행 및 결과 정리, 마지막으로 최적 튜닝 값을 이용하여 검증 데이터에 적용해 보겠다.
용해도 데이터의 회귀 분석에 대하여 이전 포스트 tidymodels 프레임 내 회귀 분석 기본 문서를 참고하자.</description>
    </item>
    
    <item>
      <title>tidymodels 프레임 내 회귀 분석 기본</title>
      <link>https://danhojin.github.io/r-blog/2020/11/19/intro-tidymodels-regression/</link>
      <pubDate>Thu, 19 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://danhojin.github.io/r-blog/2020/11/19/intro-tidymodels-regression/</guid>
      <description>tidymodels 프레임 소개 R에는 데이터 과학에 사용되는 다양한 패키지가 존재하는데, 데이터 구조나 사용 방법이 패키지별로 각각의 원리에 의하여 파편화 되어 있다. 이를 통합하고 일관성 있는 사용자 경험을 제공하고, 예측 분석에 유용한 기능을 통합하려는 노력으로 caret 패키지가 개발되었다. 한편 데이터 과학에 유용한 패키지를 모아 공통적인 디자인 철학, 문법, 자료 구조를 공유하고자 tidyverse 패키지가 개발되었다. tidymodels 패키지는 caret의 목적을 tidyverse의 데이터 구조 및 함수형 데이터 처리 방식에 따르도록 새로이 개발한 것이다.</description>
    </item>
    
    <item>
      <title>선형 회귀 모형의 변수 선택: F-검정</title>
      <link>https://danhojin.github.io/r-blog/2020/10/29/%EC%84%A0%ED%98%95-%ED%9A%8C%EA%B7%80-%EB%AA%A8%ED%98%95-%EB%B3%80%EC%88%98-f-%EA%B2%80%EC%A0%95/</link>
      <pubDate>Thu, 29 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://danhojin.github.io/r-blog/2020/10/29/%EC%84%A0%ED%98%95-%ED%9A%8C%EA%B7%80-%EB%AA%A8%ED%98%95-%EB%B3%80%EC%88%98-f-%EA%B2%80%EC%A0%95/</guid>
      <description>다중 선형 회귀에서 특징 변수 선택 선형 회귀에서 오컴의 면도날 원리는 경쟁하는 모형 혹은 모델 간에 보다 적은 수의 특징 변수를 가진 모형을 선택하는 것이 낫다는 것으로 풀어볼 수 있다. 이 원리는 과적합 문제와 연관된다. 데이터 과학에서 가장 주의해야 할 것이 과적합인데 특징 변수가 많을 수록 그 위험이 커지기 때문이다. 지금까지 보지 못 한 새로운 데이터가 등장하였을 때 특히 문제가 된다. 오컴의 면도날 원리를 적용하기 위해서는 특징 변수를 제거해도 회귀 성능이 크게 손상되지 않는다는 점을 확인할 필요가 있다.</description>
    </item>
    
  </channel>
</rss>
