<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on A Hugo website</title>
    <link>https://danhojin.github.io/r-blog/post/</link>
    <description>Recent content in Posts on A Hugo website</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ko-KR</language>
    <lastBuildDate>Thu, 19 Nov 2020 00:00:00 +0000</lastBuildDate><atom:link href="https://danhojin.github.io/r-blog/post/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>tidymodels 프레임 내 회귀 분석 기본</title>
      <link>https://danhojin.github.io/r-blog/2020/11/19/intro-tidymodels-regression/</link>
      <pubDate>Thu, 19 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://danhojin.github.io/r-blog/2020/11/19/intro-tidymodels-regression/</guid>
      <description>tidymodels 프레임 소개 R에는 데이터 과학에 사용되는 다양한 패키지가 존재하는데, 데이터 구조나 사용 방법이 패키지별로 각각의 원리에 의하여 파편화 되어 있다. 이를 통합하고 일관성 있는 사용자 경험을 제공하고, 예측 분석에 유용한 기능을 통합하려는 노력으로 caret 패키지가 개발되었다. 한편 데이터 과학에 유용한 패키지를 모아 공통적인 디자인 철학, 문법, 자료 구조를 공유하고자 tidyverse 패키지가 개발되었다. tidymodels 패키지는 caret의 목적을 tidyverse의 데이터 구조 및 함수형 데이터 처리 방식에 따르도록 새로이 개발한 것이다.</description>
    </item>
    
    <item>
      <title>교호 작용 선택을 위한 라소 회귀 - glinternet 소개</title>
      <link>https://danhojin.github.io/r-blog/2020/11/14/%EA%B5%90%ED%98%B8-%EC%9E%91%EC%9A%A9-%EB%9D%BC%EC%86%8C-%ED%9A%8C%EA%B7%80-glinternet-%EC%86%8C%EA%B0%9C/</link>
      <pubDate>Sat, 14 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://danhojin.github.io/r-blog/2020/11/14/%EA%B5%90%ED%98%B8-%EC%9E%91%EC%9A%A9-%EB%9D%BC%EC%86%8C-%ED%9A%8C%EA%B7%80-glinternet-%EC%86%8C%EA%B0%9C/</guid>
      <description>glinternet 라소(lasso)나 능형 회귀(ridge regression) 방법은 glmnet 패키지에 잘 구현되어 있으며, 이를 활용하면 특징 변수의 선택을 체계적으로 수행할 수 있다[1]. 이 패키지에는 교차 검증이 구현되어 있어 라그랑주 승수(lagrange multiplier)와 MSE 평균 및 MSE의 분산 관계를 파악할 수 있다. 그리고 그 관계로부터 적절히 선택된 변수를 제안해 준다. 하지만 교호 효과가 유의하나 주 효과가 유의하지 않는 경우에 glmnet은 주 효과를 제거해 버릴 수 있어 문제가 생긴다. 일반적으로 모델 해석을 분명하게 제시하기 위해 유의하지 않더라도 주 효과를 제거하지 않는데[2], 이런 문제를 다루기 위해 glinternet 패키지가 개발되었다[3].</description>
    </item>
    
    <item>
      <title>선형 혼합 모형의 소개</title>
      <link>https://danhojin.github.io/r-blog/2020/11/09/%EC%84%A0%ED%98%95-%ED%98%BC%ED%95%A9-%EB%AA%A8%ED%98%95-%EC%86%8C%EA%B0%9C/</link>
      <pubDate>Mon, 09 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://danhojin.github.io/r-blog/2020/11/09/%EC%84%A0%ED%98%95-%ED%98%BC%ED%95%A9-%EB%AA%A8%ED%98%95-%EC%86%8C%EA%B0%9C/</guid>
      <description>혼합 모형 개념의 소개: Rail - 선로 내 음파 전달 시험 당신이 어떤 중요한 실험을 준비하고 있다고 해보자. 시편 하나를 준비하는데 비용이 크게 든다면 통계적으로 유의미한 수의 시편을 확보할 수가 없다. 이렇게 준비된 시편 하나에 여러번 반복 측정을 수행해도 시편 간 측정치의 차이가 시편 내 측정치의 차이보다 더 큰 경우가 생길 수 있다. 이와 같이 데이터의 구조는 일원배치 분산 분석(one-way anova)과 비슷하나 처치의 효과에는 관심이 없을 때 혼합 모형이 작동한다.</description>
    </item>
    
    <item>
      <title>선형 회귀 모형의 변수 선택: F-검정</title>
      <link>https://danhojin.github.io/r-blog/2020/10/29/%EC%84%A0%ED%98%95-%ED%9A%8C%EA%B7%80-%EB%AA%A8%ED%98%95-%EB%B3%80%EC%88%98-f-%EA%B2%80%EC%A0%95/</link>
      <pubDate>Thu, 29 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://danhojin.github.io/r-blog/2020/10/29/%EC%84%A0%ED%98%95-%ED%9A%8C%EA%B7%80-%EB%AA%A8%ED%98%95-%EB%B3%80%EC%88%98-f-%EA%B2%80%EC%A0%95/</guid>
      <description>다중 선형 회귀에서 특징 변수 선택 선형 회귀에서 오컴의 면도날 원리는 경쟁하는 모형 혹은 모델 간에 보다 적은 수의 특징 변수를 가진 모형을 선택하는 것이 낫다는 것으로 풀어볼 수 있다. 이 원리는 과적합 문제와 연관된다. 데이터 과학에서 가장 주의해야 할 것이 과적합인데 특징 변수가 많을 수록 그 위험이 커지기 때문이다. 지금까지 보지 못 한 새로운 데이터가 등장하였을 때 특히 문제가 된다. 오컴의 면도날 원리를 적용하기 위해서는 특징 변수를 제거해도 회귀 성능이 크게 손상되지 않는다는 점을 확인할 필요가 있다.</description>
    </item>
    
  </channel>
</rss>
